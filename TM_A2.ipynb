{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TM A2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOvO92zYTx1rWypr3oxHvKQ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/PawinData/TM/blob/main/TM_A2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vX5d8HiZ07-T",
        "outputId": "c970adab-00b8-4460-8246-abd5d93fa07b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!pip install sklearn_crfsuite"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting sklearn_crfsuite\n",
            "  Downloading https://files.pythonhosted.org/packages/25/74/5b7befa513482e6dee1f3dd68171a6c9dfc14c0eaa00f885ffeba54fe9b0/sklearn_crfsuite-0.3.6-py2.py3-none-any.whl\n",
            "Requirement already satisfied: tqdm>=2.0 in /usr/local/lib/python3.6/dist-packages (from sklearn_crfsuite) (4.41.1)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.6/dist-packages (from sklearn_crfsuite) (0.8.7)\n",
            "Collecting python-crfsuite>=0.8.3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/95/99/869dde6dbf3e0d07a013c8eebfb0a3d30776334e0097f8432b631a9a3a19/python_crfsuite-0.9.7-cp36-cp36m-manylinux1_x86_64.whl (743kB)\n",
            "\u001b[K     |████████████████████████████████| 747kB 4.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sklearn_crfsuite) (1.15.0)\n",
            "Installing collected packages: python-crfsuite, sklearn-crfsuite\n",
            "Successfully installed python-crfsuite-0.9.7 sklearn-crfsuite-0.3.6\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "isX6o2-ez5on"
      },
      "source": [
        "\n",
        "from itertools import chain\n",
        "import matplotlib.pyplot as plt\n",
        "plt.style.use('ggplot')\n",
        "\n",
        "import sklearn"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AC3a9zfN_Ffe"
      },
      "source": [
        "# Pre-processing\n",
        "\n",
        "Build the [reader of dataset](https://www.nltk.org/_modules/nltk/corpus/reader/conll.html) and represent every sentence as a list of tuple (word, POS, OBI)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gzxmxGkYGJQp",
        "outputId": "e7835f5e-3eed-4997-8900-6ad4acfdc34e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import nltk\n",
        "#nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "from nltk.corpus.reader.conll import ConllCorpusReader\n",
        "# a .ConLL file reader\n",
        "READER = ConllCorpusReader(root=\"./\", fileids=\".conll\", columntypes=('words','pos','tree','chunk','ne','srl','ignore'))"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7CH2tvmDNOdm"
      },
      "source": [
        "def load(filename):\n",
        "    word_pos = [nltk.pos_tag(sentence) for sentence in READER.sents(filename)]\n",
        "    word_obi = list(READER.tagged_sents(filename))\n",
        "    return [[(a,b,d) for (a,b),(c,d) in zip(lst1, lst2)] for lst1,lst2 in zip(word_pos,word_obi)]\n",
        "\n",
        "# training set\n",
        "Train_sents = load(\"wnut17train.conll\")\n",
        "# test set\n",
        "Test_sents = load(\"emerging.test.annotated\")"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j-QMFmWWP7mP"
      },
      "source": [
        "# Development set\n",
        "word_pos = [nltk.pos_tag(sentence) for sentence in READER.sents(\"emerging.dev.conll\")[:1008]]\n",
        "word_obi = list(READER.tagged_sents(\"emerging.dev.conll\")[:1008])\n",
        "Dev_sents = [[(a,b,d) for (a,b),(c,d) in zip(lst1, lst2)] for lst1,lst2 in zip(word_pos,word_obi)]"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OMhkN7j-KGEB"
      },
      "source": [
        "# Baseline\n",
        "\n",
        "Extract the OBI label and the following features from each word in a sentence. Build a model of Conditional Random Field (**CRF**) on the training data and evaluate its performance on the test set. As a baseline, generate **transition features** that associate all of possible label pairs and **iterate $100$ times at most** by the **L-BFGS algorithm of Gradient Descent** with Elastic-Net regularization to fit model parameters; in specific, **L1-regularization** is controlled by $c_1 = 0.1$ and **L2-regularization** by $c_2 = 0.1$.\n",
        "\n",
        "**Features:**\n",
        "1.   **Word Identity**: lowercased form\n",
        "2.   **Word Suffix**: the last two and three characters\n",
        "3.   **Word Shape**: whether a word is a digit, is uppercased, or starts with an uppercase character\n",
        "4.   **Part-of-Speech Tag**: noun, verb, adjective, e.t.c\n",
        "5.   **BOS**: whether a word is the start of sentence\n",
        "6.   **EOS**: whether a word is the end of sentence\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Quassgy2AgN9"
      },
      "source": [
        "from sklearn_crfsuite import CRF, metrics"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y9kFWpxhKLsi"
      },
      "source": [
        "# extract features and labels\n",
        "def word2features(sent, i):\n",
        "    word = sent[i][0]\n",
        "    postag = sent[i][1]\n",
        "\n",
        "    features = {'bias': 1.0,\n",
        "                'word.lower()': word.lower(),        # word identity\n",
        "                'word[-3:]': word[-3:],              # word suffix \n",
        "                'word[-2:]': word[-2:],\n",
        "                'word.isupper()': word.isupper(),    # word shape\n",
        "                'word.istitle()': word.istitle(),\n",
        "                'word.isdigit()': word.isdigit(),\n",
        "                'postag': postag,                    # POS tag\n",
        "                'postag[:2]': postag[:2],\n",
        "               }\n",
        "    if i > 0:\n",
        "        word1 = sent[i-1][0]\n",
        "        postag1 = sent[i-1][1]\n",
        "        features.update({'-1:word.lower()': word1.lower(),\n",
        "                          '-1:word.istitle()': word1.istitle(),\n",
        "                          '-1:word.isupper()': word1.isupper(),\n",
        "                          '-1:postag': postag1,\n",
        "                          '-1:postag[:2]': postag1[:2],\n",
        "                      })\n",
        "    else:\n",
        "        features['BOS'] = True                      # BOS\n",
        "\n",
        "    if i < len(sent)-1:\n",
        "        word1 = sent[i+1][0]\n",
        "        postag1 = sent[i+1][1]\n",
        "        features.update({'+1:word.lower()': word1.lower(),\n",
        "                         '+1:word.istitle()': word1.istitle(),\n",
        "                         '+1:word.isupper()': word1.isupper(),\n",
        "                         '+1:postag': postag1,\n",
        "                         '+1:postag[:2]': postag1[:2],\n",
        "                       })\n",
        "    else:\n",
        "        features['EOS'] = True                     # EOS\n",
        "\n",
        "    return features\n",
        "\n",
        "\n",
        "def sent2features(sent):\n",
        "    return [word2features(sent, i) for i in range(len(sent))]\n",
        "\n",
        "def sent2labels(sent):\n",
        "    return [label for token, postag, label in sent]\n",
        "\n",
        "def setup(data_sents):\n",
        "    return [sent2features(s) for s in data_sents], [sent2labels(s) for s in data_sents]"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s8G9DBEvZwbb"
      },
      "source": [
        "# set up datasets\n",
        "X_train,y_train = setup(Train_sents)\n",
        "X_test, y_test  = setup(Test_sents)\n",
        "X_dev,  y_dev   = setup(Dev_sents)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lQFD7vSmKHLR"
      },
      "source": [
        "# training\n",
        "baseline = CRF(algorithm='lbfgs', c1=0.1, c2=0.1, max_iterations=100, all_possible_transitions=True)\n",
        "baseline.fit(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z0Wz1buRAgTw",
        "outputId": "f301fed2-6028-4c5e-9e8e-9bd2e5f8a9de",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# evaluate\n",
        "y_pred = baseline.predict(X_test)\n",
        "\n",
        "labels = list(baseline.classes_)\n",
        "labels.remove('O')\n",
        "sorted_labels = sorted(labels, key = lambda name: (name[1:], name[0]))\n",
        "print(metrics.flat_classification_report(y_test, y_pred, labels=sorted_labels, digits=4))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                 precision    recall  f1-score   support\n",
            "\n",
            "  B-corporation     0.0000    0.0000    0.0000        66\n",
            "  I-corporation     0.0000    0.0000    0.0000        22\n",
            "B-creative-work     0.3333    0.0352    0.0637       142\n",
            "I-creative-work     0.2963    0.0367    0.0653       218\n",
            "        B-group     0.3000    0.0364    0.0649       165\n",
            "        I-group     0.3571    0.0714    0.1190        70\n",
            "     B-location     0.3846    0.2333    0.2905       150\n",
            "     I-location     0.2308    0.0638    0.1000        94\n",
            "       B-person     0.5514    0.1375    0.2201       429\n",
            "       I-person     0.5472    0.2214    0.3152       131\n",
            "      B-product     0.6000    0.0236    0.0455       127\n",
            "      I-product     0.3750    0.0476    0.0845       126\n",
            "\n",
            "      micro avg     0.4297    0.0931    0.1530      1740\n",
            "      macro avg     0.3313    0.0756    0.1141      1740\n",
            "   weighted avg     0.4009    0.0931    0.1422      1740\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gkMZPHaMAgmW"
      },
      "source": [
        "The baseline run performs rather poorly for recognizing B-tags and I-tags. Recall scores are particularly low.\n",
        "\n",
        "# Hyperparameters Optimization\n",
        "\n",
        "Allow $1000$ iterations and conduct a grid search for better algorithm and optimal hyperparameters of the CRF model. Candidate algorithms are **Gradient Descent with L-BFGS method** and **Stochastic Gradient Descent with L2 regularization**, and let $c_1 \\sim \\exp(-2t)$ and $c_2 \\sim \\exp(-20t)$. Use the development set for testing and find the combination of hyperparameters that performs the best on it."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YgYyBiLWAlCa"
      },
      "source": [
        "import scipy.stats\n",
        "from sklearn.metrics import make_scorer\n",
        "from sklearn.model_selection import RandomizedSearchCV, cross_val_score"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9BUxKB05AmBY",
        "outputId": "4794ae6c-1e46-481c-c9a6-af317efcbb98",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# grid search of hyperparameters\n",
        "crf = CRF(max_iterations=1000, all_possible_transitions=True)\n",
        "params_space = {'algorithm':['lbfgs','l2sgd'], 'c1': scipy.stats.expon(scale=0.5), 'c2': scipy.stats.expon(scale=0.05),}\n",
        "\n",
        "rs = RandomizedSearchCV(crf, params_space, \n",
        "                        cv = 5,\n",
        "                        verbose = 1,\n",
        "                        n_jobs = -1,\n",
        "                        n_iter = 50,\n",
        "                        scoring = make_scorer(metrics.flat_f1_score, average='weighted', labels=labels)\n",
        "                       )\n",
        "rs.fit(X=X_train, y=y_train, X_dev=X_dev, y_dev=y_dev)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/base.py:197: FutureWarning: From version 0.24, get_params will raise an AttributeError if a parameter cannot be retrieved as an instance attribute. Previously it would return None.\n",
            "  FutureWarning)\n",
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  46 tasks      | elapsed: 69.5min\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SCGHmQCaAmIb",
        "outputId": "faf920fa-6262-49a6-82d1-d0c7275092ae",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# optimization results\n",
        "print('Best Hyperparameters:', rs.best_params_)\n",
        "print('Best Cross-Validation Score:', rs.best_score_)\n",
        "print('Model Size: {:0.2f}M'.format(rs.best_estimator_.size_ / 10**6))"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "best params: {'c1': 0.0016658821336182827, 'c2': 0.00670123074384953}\n",
            "best CV score: 0.39981334218537723\n",
            "model size: 0.63M\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uTJvboJNAmSV"
      },
      "source": [
        "# evaluate on test set\n",
        "optmz = CRF(algorithm=, c1=, c2=, max_iterations=1000, all_possible_transitions=True)\n",
        "optmz.fit(X_train, y_train)\n",
        "y_pred = optmz.predict(X_test)\n",
        "labels = list(optmz.classes_)\n",
        "labels.remove('O')\n",
        "sorted_labels = sorted(labels, key = lambda name: (name[1:], name[0]))\n",
        "print(metrics.flat_classification_report(y_test, y_pred, labels=sorted_labels, digits=4))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tG3pseMNAnV9"
      },
      "source": [
        "# Experiments with Features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dTsaLQ6LArY3"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}